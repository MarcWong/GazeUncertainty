{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys,os\n",
    "sys.path.append(\"..\")\n",
    "from glob import glob\n",
    "from shutil import rmtree\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32685 34093\n",
      "0.875202692366529\n",
      "0.8932625465638108\n"
     ]
    }
   ],
   "source": [
    "def vistype(desc: pd.Series):\n",
    "    visname = desc.strip('.png')\n",
    "    visname = visname.strip('.jpg')\n",
    "    json_file = os.path.join('/netpool/homes/wangyo/Dataset/VisQA/merged/qa', visname + '.json')\n",
    "    json_file = open(json_file)\n",
    "    visjson = json.load(json_file)\n",
    "    json_file.close()\n",
    "    return visjson['vistype']\n",
    "\n",
    "def excludeImage(desc: pd.Series, typen):\n",
    "    src = f\"/netpool/homes/wangyo/Projects/scanpath-uncertainty/VisQA+/included_{typen}\"\n",
    "    if not os.path.exists(src): return desc\n",
    "    filelist=pd.read_csv(src, header=None)\n",
    "\n",
    "    df = pd.DataFrame(columns=desc.columns)\n",
    "\n",
    "    for id, row in filelist.iterrows():\n",
    "        df = df.append(desc[desc['image_name'] == row[0]])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "base_path = '/netpool/homes/wangyo/Dataset/VisQA/eyetracking/Results'\n",
    "subjects_path = glob(os.path.join(\n",
    "    f\"{base_path}/*/\", \"*\", \"\"))\n",
    "subjects_path = [os.path.abspath(path) for path in subjects_path]\n",
    "\n",
    "good_sum = 0\n",
    "good_true = 0\n",
    "bad_sum = 0\n",
    "bad_true = 0\n",
    "for path in subjects_path:\n",
    "    pname = path.split('/')[-1]\n",
    "    #good = f\"{path}/{pname}_images_with_fixations_and_elems_enlarge_0.csv\"\n",
    "    fgood = f\"{path}/{pname}_images_with_fixations_and_elems_enlarge_0.9degree.csv\"\n",
    "    fbad = f\"{path}/{pname}_images_with_fixations_and_elems_enlarge_1degree.csv\"\n",
    "    if(not os.path.exists(fgood) or not os.path.exists(fbad)): continue\n",
    "    tmp_good=pd.read_csv(fgood)\n",
    "    tmp_bad=pd.read_csv(fbad)\n",
    "    tmp_good = tmp_good[tmp_good['stage'] == 'enc']\n",
    "    tmp_bad = tmp_bad[tmp_bad['stage'] == 'enc']\n",
    "\n",
    "    # exclude the bad images out\n",
    "    #excludeImage(tmp_good, 'bar')\n",
    "    excludeImage(tmp_good, 'line')\n",
    "    #excludeImage(tmp_good, 'scatter')\n",
    "    #excludeImage(tmp_good, 'pie')\n",
    "\n",
    "    # apply the vistype\n",
    "    tmp_good['image_name'] = tmp_good['image_name'].apply(vistype)\n",
    "    tmp_good = tmp_good[tmp_good['image_name'] == 'line']\n",
    "    tmp_bad['image_name'] = tmp_bad['image_name'].apply(vistype)\n",
    "    tmp_bad = tmp_bad[tmp_bad['image_name'] == 'line']\n",
    "\n",
    "    gtrue = (tmp_good['contains']==True).sum()\n",
    "    gfalse = (tmp_good['contains']==False).sum()\n",
    "    btrue = (tmp_bad['contains']==True).sum()\n",
    "    bfalse = (tmp_bad['contains']==False).sum()\n",
    "    good_sum += gtrue\n",
    "    good_sum += gfalse\n",
    "    good_true += gtrue\n",
    "    bad_sum += btrue\n",
    "    bad_sum += bfalse\n",
    "    bad_true += btrue\n",
    "\n",
    "\n",
    "print(good_sum, bad_sum)\n",
    "print(good_true/good_sum)\n",
    "print(bad_true/bad_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10033467208545055"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tan(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVG\n",
    "## 0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5\n",
    "### 55, 61, 66, 70, 74, 77, 81, 84.7, 88\n",
    "## 0.6, 0.7, 0.8, 0.9, 1.0\n",
    "### 90.5, 92.5, 94, 95.1, 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter\n",
    "## 0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5\n",
    "### 46, 52, 58, 63, 68, 72, 77, 82, 86\n",
    "## 0.6, 0.7, 0.8, 0.9, 1.0\n",
    "### 89.5, 92, 94.1, 95.4, 96.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# line\n",
    "## 0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5\n",
    "### 41, 46, 51, 55, 59, 63, 67, 71, 76\n",
    "## 0.6, 0.7, 0.8, 0.9, 1.0\n",
    "### 79.5, 82.8, 85.3, 87.5, 89.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bar\n",
    "## 0,   0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5\n",
    "### 55.7, 62.3, 68.2, 72.9, 77.1, 80.4, 83.5, 87.9, 91.1\n",
    "\n",
    "## 0.6, 0.7, 0.8, 0.9, 1.0\n",
    "### 93.5, 95.1, 96.1, 97.0, 97.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pie\n",
    "## 0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5\n",
    "### 64, 67, 71, 74, 77, 79, 83, 85, 88\n",
    "## 0.6, 0.7, 0.8, 0.9, 1.0\n",
    "### 89.6, 91.4, 93.0, 94.0, 94.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
